{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런(scikit-learn) 기본 지식\n",
    "\n",
    "사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리입니다.\n",
    "파이썬 기반의 머신러닝은 곧 사이킷런으로 개발하는 것을 의미할 정도로 오랜 기간 사용되고 있으며 머신러닝을 위한 가장 쉽고 효율적인 개발 라이브러리를 제공합니다. 최근에는 **텐스플로, 케라스** 등 딥러닝 전문 라이브러리가 강세이지만 여전히 많은 데이터 분석가가 의존하는 ML 라이브러리입니다.\n",
    "\n",
    "**사이킷런의 특징**\n",
    "- 쉽고 가장 파이썬스러운 API 제공\n",
    "- 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편리한 프레임워크와 API 제공\n",
    "- 오랜 기간 실전 환경에서 검증됐으며, 매우 많은 환경에서 사용되는 성숙한 라이브러리\n",
    "\n",
    "\n",
    "Anaconda설치 시 자동으로 사이킷런까지 설치되므로 별도의 설치는 필요 없음. 만약 제거되어 별도로 다시 설치해야할 경우 pip / conda로 설치 가능하며 가급적이면 conda로 셋업할 것을 권장함.\n",
    "\n",
    "\n",
    "### 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기\n",
    "\n",
    "붓꽃 데이터 세트로 붓꽃의 품종을 분류(Classification)하기\n",
    "\n",
    "붓꽃 데이터 세트 : 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처(Feature)\n",
    "\n",
    "#### 분류 (Classification)\n",
    "\n",
    "대표적인 지도 학습(Supervised Learning) 방법 중 하나이다. 지도학습이란 학습을 위한 다양한 피처와 분류 결정값인 레이블(Lable) 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측하는 방식이다. 이 때 학습을 위해 주어진 데이터 세트를 학습 데이터 세트(Training Dataset), 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트를 테스트 데이터 세트(Test Dataset)로 지칭함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn 패키지 내의 모듈명은 sklearn으로 시작\n",
    "- sklearn.datasets 내의 모듈 : scikit-learn에서 자체적으로 제공하는 dataset을 생성하는 모듈의 모임\n",
    "- sklearn.tree 내의 모듈 : 트리 기반 ML 알고리즘을 구현한 클래스의 모임\n",
    "- sklearn.model_selection : training data와 test data로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임\n",
    "\n",
    "Hyperparameter란? 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터들을 통칭! 이를 통해 머신러닝 알고리즘의 성능을 tuning할 수 있음.\n",
    "\n",
    "\n",
    "- 붓꽃 dataset 생성 : load_iris()\n",
    "- ML알고리즘 : 의사 결정 트리(Decision Tress) 사용 -> DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명 :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩합니다.\n",
    "iris = load_iris()\n",
    "\n",
    "# iris.data는 Iris 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있습니다.\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.target은 붓꽃 데이터 세트에서 lable(결정 값) 데이터를 numpy로 가지고 있습니다.\n",
    "iris_label = iris.target\n",
    "print('iris target값 : ', iris_label)\n",
    "print('iris target명 : ', iris.target_names)\n",
    "\n",
    "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다.\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split() API\n",
    "**학습용 데이터와 테스트용 데이터 분리**\n",
    "\n",
    "- training data로 학습된 모델이 얼마나 뛰어난 성능을 가지는지 평가하려면 test dataset이 필요하기 때문.\n",
    "- test_size 파라미터 입력 값의 분할로 쉽게 분할 가능\n",
    "- e.g) test_size = 0.2 -> 전체 데이터 중 test data가 20%, training data가 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parameter**\n",
    "- iris_data : feature dataset\n",
    "- iris_lable : label dataset\n",
    "- test_size : 전체 데이터 세트 중 test dataset의 비율\n",
    "- random_state : 호출할 때마다 같은 training/test 용 dataset를 생성하기 위해 주어지는 난수 발생 값. -> train_test_split()는 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 training/test 용 데이터를 만들기 때문에!\n",
    "\n",
    "\n",
    "**return value**\n",
    "- X_train : train용 feature dataset\n",
    "- X_test : test용 feature dataset\n",
    "- y_train : train용 label dataset\n",
    "- y_test : test용 label dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런의 의사 결정 트리 클래스인 DecisionTreeClassifier를 객체로 생성.\n",
    "\n",
    "생성된 객체의 **fit()**메서드에 학습용 feature data 속성과 lable dataset를 입력해 호출하면 학습 수행!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=11, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict()**\n",
    "\n",
    "예측은 반드시 training data가 아닌 다른 data를 이용해야 함! 일반적으로 test dataset이용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료된 DecisionTreeClassifier 객체에서 test dataset로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**성능 평가**\n",
    "머신러닝 모델의 성능 평가 방법은 여러 가지가 있음.\n",
    "이번에는 정확도를 측정해보자.\n",
    "\n",
    "정확도란? 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표.\n",
    "\n",
    "**acuracy_score()**\n",
    "첫 번째 파라미터 값으로 실제 lable dataset, 두 번째 파라미터 값으로 예측 lable dataset 입력!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런의 기반 프레임워크 익히기\n",
    "\n",
    "#### Estimator 이해 및 fit(), predict() 메서드\n",
    "\n",
    "- 모델 학습을 위해서 fit(), 학습된 모델의 예측을 위해 predict() 메서드 제공.\n",
    "- 지도학습의 주요 두 축인 분류(Classification)와 회귀(Regression)의 다양한 알고리즘을 구현한 모든 사이킷 클래스는 fit()과 predict()만을 이용해 간단하게 학습과 예측 결과 반환\n",
    "\n",
    "**Estimator**\n",
    "- 분류 알고리즘을 구현한 클래스 **Classifier**와 회귀 알고리즘을 구현한 클래스 **Regressor**를 합쳐서 **Estimator**라고 부름. \n",
    "- Estimator 클래스 내부에 fit()과 predict() 구현\n",
    "- cross_val_score()와 같은 evaluation 함수, GridSearchCV와 같은 Hyperparemeter tuning을 지원하는 클래스의 경우 이 Estimator를 인자로 받음.\n",
    "- 인자로 받은 Estimator에 대해서 cross_val_score(), GridSearchCV.fit()함수 내에서 이 Estimator의 fit()과 predict()를 호출해서 평가하거나 hyper parameter tuning 수행\n",
    "\n",
    "\n",
    "- 비지도학습(Unsupervised Learning)인 차원축소, 클러스터링, 피처 추출(Feature Extraction) 등을 구현한 클래스 역시 대부분 fit()과 transform()적용\n",
    "- 이때 fit()은 지도학습의 fit()과 같이 학습을 의미하는 것이 아니라 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞춘ㄴ 작업\n",
    "- fit()으로 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등의 실제 작업은 transform()으로 수행\n",
    "- fit()과 transform()을 하나로 결합한 fit_transform()도 제공함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킷런의 주요 모듈\n",
    "\n",
    "**예제 데이터**\n",
    "- sklearn.datasets : 사이킷런에 내장되어 예제로 제공하는 데이터 세트\n",
    "\n",
    "\n",
    "**피처 처리**\n",
    "- sklearn.preprocessing : 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링 등)\n",
    "- sklearn.feature_selection : 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공\n",
    "- sklearn.feature_extraction : 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨. 예를 들어 텍스트 데이터에서 Count Vectorizer나 Tf-Idf Vectorizer 등을 생성하는 기능 제공. 텍스트 데이터의 피처 추출은 - - sklearn.feature_extraction.text 모듈에, 이미지 데이터의 피처 추출은 sklearn.feature_extraion.image 모듈에 지원 API가 있음\n",
    "\n",
    "\n",
    "**피처 처리 & 차원 축소**\n",
    "- sklearn.decomposition : 차원 축소와 관련한 알고리즘을 지원하는 모듈임. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능을 수행할 수 있음\n",
    "\n",
    "\n",
    "**데이터 분리, 검증 & 파라미터 튜닝**\n",
    "- sklearn.model_selection : 교차 검증을 위한 학습용/테스트용 분리, 그리드 서치(GridSearch)로 최적 파라미터 추출 등의 API 제공\n",
    "\n",
    "\n",
    "**평가**\n",
    "- sklearn.metrics : 분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법 제공(Accuracy, Precision, Recall ROC-AUC, RMSE 등 제공)\n",
    "\n",
    "\n",
    "**ML 알고리즘**\n",
    "- sklearn.ensemble : 앙상블 알고리즘 제공(random forest, AdaBoost, Gradient Boosting 등)\n",
    "- sklearn.linear_model : 주로 선형 회귀, 릿지(Ridge), 라쏘(Lasso) 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원. 또한 SGD(Stochastic Gradient Descent) 관련 알고리즘도 제공\n",
    "- sklearn.naive_bayes : 나이브 베이즈 알고리즘 제공. 가우시안 NB, 다항 분포 NB 등.\n",
    "- sklearn.neighbors : 최근접 이웃 알고리즘 제공(K-NN 등)\n",
    "- sklearn.svm : 서포트 벡터 머신 알고리즘 제공\n",
    "- sklearn.tree : 의사 결정 트리 알고리즘 제공\n",
    "- sklearn.cluster : 비지도 클러스터링 알고리즘 제공(k-means, 계층형, DBSCAN 등)\n",
    "\n",
    "\n",
    "**유틸리티**\n",
    "- sklearn.pipeline : 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내장된 예제 데이터 세트\n",
    "\n",
    "- datasets.load_boston() : 회귀 용도이며, 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트\n",
    "- datasets.load_breast_cancer() : 분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트\n",
    "- datasets.load_diabetes() : 회귀 용도이며, 당뇨 데이터 세트\n",
    "- datasets.load_digits() : 분류 용도이며, 0에서 9까지의 숫자의 이미지 픽셀 데이터 세트\n",
    "- datasets.load_iris() : 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트\n",
    "\n",
    "fetch 계열의 명령은 데이터의 크기가 커서 패키지에 처음부터 저장돼 있지 않고 인터넷에서 내려받아 scikit_learn_data라는 서브 디렉터리에 저장한 후 불러들여 사용가능\n",
    "- fetch_covtype() : 회귀 분석용 토지 조사 자료\n",
    "- fetch_20newsgroups() : 뉴스 그룹 텍스트 자료\n",
    "- fetch_olivetti_faces() : 얼굴 이미지 자료\n",
    "- fetch_lfw_people() : 얼굴 이미지 자료\n",
    "- fetch_lfw_pairs() : 얼굴 이미지 자료\n",
    "- fetch_rcv1() : 로이터 뉴스 말뭉치\n",
    "- fetch_mldata() : ML 웹사이트에서 다운로드\n",
    "\n",
    "분류와 클러스터링을 위한 표본 데이터 생성기\n",
    "- datasets.make_classification() : 분류를 위한 데이터 세트를 만듭니다. 특히 높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성해 줍니다.\n",
    "- datasets.make_blobs() : 클러스터링을 위한 데이터 세트를 무작위로 생성해 줍니다. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 세트를 쉽게 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunch 클래스란? 파이썬 딕셔너리 자료형과 유사. 데이터 세트에 내장돼 있는 대부분의 데이터 세트는 이와 같이 딕셔너리 형태의 값을 반환함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들 :  dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들 : ', keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 키는 feature들의 데이터 값을 가리키므로 **데이터세트.data(또는 데이터세트['data'])**를 이용해서 feature data값 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names의 type :  <class 'list'>\n",
      "\n",
      " feature_names의 shape :  4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type :  <class 'numpy.ndarray'>\n",
      "\n",
      " target_names의 shape :  3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type :  <class 'numpy.ndarray'>\n",
      "\n",
      " data의 shape :  2\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target의 type :  <class 'numpy.ndarray'>\n",
      "\n",
      " target의 shape :  1\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('\\n feature_names의 type : ', type(iris_data.feature_names))\n",
    "print('\\n feature_names의 shape : ', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type : ', type(iris_data.target_names))\n",
    "print('\\n target_names의 shape : ', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type : ', type(iris_data.data))\n",
    "print('\\n data의 shape : ', len(iris_data.data.shape))\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n target의 type : ', type(iris_data.target))\n",
    "print('\\n target의 shape : ', len(iris_data.target.shape))\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection 모듈 소개\n",
    "\n",
    "model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 hyperparameter를 튜닝하기 위한 다양한 함수와 클래스를 제공.\n",
    "\n",
    "#### 학습/테스트 데이터 세트 분리 : train_test_split()\n",
    "- test_size : 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가(default = 0.25)\n",
    "- train_size : 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가(보통 test_size사용)\n",
    "- shuffl : data를 분리하기 전에 미리 섞을지 결정, 데이터를 분산시켜 좀 더 효율적인 dataset만드는데 사용 (defatul = True)\n",
    "- random_state : 호출할 때마다 동일한 학습/테스트용 dataset를 생성하기 위해 주어지는 난수 값. \n",
    "- 반환값 : 튜플 형태. 순차적으로 학습용 데이터의 feature dataset, 테스트용 데이터의 feature dataset, 학습용 데이터의 lable dataset, 테스트용 데이터의 lable dataset 반환\n",
    "\n",
    "\n",
    "만약 나누지 않고 학습 데이터 세트로만 학습하고 예측한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도 : ', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 세트를 전체의 30, random_state = 121로 변경\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state = 121)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증 (Cross-validation)\n",
    "\n",
    "테스트 데이터가 별도로 있다하더라도 과적합(Overfitting)이 생길 수 있음.\n",
    "\n",
    "Overfitting이란? : 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에 예측 성능이 과도하게 떨어지는 것\n",
    "이러한 문제를 해결하기 위해 교차 검증 이용!\n",
    "\n",
    "#### k-fold cross validation\n",
    "\n",
    "k개의 데이터 폴드 세트를 만들어서 k번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 :  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기 : ', features.shape[0])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.8667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 변환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Startified K Fold\n",
    "\n",
    "불균형한(imbalanced) 분포도를 가진 label(결정 클래스) 데이터 집합을 위한 K-Fold 방식.\n",
    "불균형한 분포도를 가진 lable data 집합은 특정 lable 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 의미. \n",
    "\n",
    "e.g) 대출사기 : 대부분의 데이터는 정상 대출, 대출 사기는 전체의 약 0.0001%로 아주 작은 확률. 따라서 제대로 레이블 값을 반영하지 못하는 경우가 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 이슈가 발생하는 현상을 도출하기 위해 3개의 폴드 세트를 생성하고, 각 교차 검증 시마다 생성되는 학습/ 검증 레이블 데이터 값의 분포도 확인\n",
    "\n",
    "kfold = KFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index, in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
    "    iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 첫번째 교차 검증을 살펴보면 학습 레이블의 1, 2 값이 각각 50개가 추출, 검증 레이블의 0값이 50개 이므로 0의 경우는 전혀 학습하지 못함. 따라서 예측 정확도는 0이 될 수밖에 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StartifiedKFold를 사용하는 방법은 KFold를 사용하는 방법과 비슷함. \n",
    "단 하나 큰 차이는 StartifiedKFold는 레이블 데이터 분포도에 따라 학습 / 검증 데이터를 나누기 때문에 split() 메서드에 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 필요하다는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 0.98, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "## 교차 검증별 정확도 :  [0.98]\n",
      "## 평균 검증 정확도 :  0.98\n",
      "\n",
      "#2 교차 검증 정확도 : 0.94, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "## 교차 검증별 정확도 :  [0.98 0.94]\n",
      "## 평균 검증 정확도 :  0.96\n",
      "\n",
      "#3 교차 검증 정확도 : 0.98, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도 :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "# StratifiedKFold의 split() 호출 시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 반복 시마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    # 교차 검증별 정확도 및 평균 정확도 계산\n",
    "    print('\\n## 교차 검증별 정확도 : ', np.round(cv_accuracy, 4))\n",
    "    print('## 평균 검증 정확도 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 분류(Classification)에서의 교차 검증은 K-Fold가 아니라 Stratified K-Fold로 분할돼야 함.\n",
    "회귀(Regression)에서는 Stratified K-Fold가 지원되지 않음.\n",
    "\n",
    "이유는 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없기 때문!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증을 보다 간편하게 - cross_val_score()\n",
    "\n",
    "KFold로 데이터를 학습하고 예측하는 코드\n",
    "1. 폴드 세트를 설정\n",
    "2. for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출\n",
    "3. 반복적으로 학습과 예측 수행하고 예측 성능 반환\n",
    "\n",
    "-> cross_val_score()는 이런 일련의 과정을 한꺼번에 수행해주는 API\n",
    "\n",
    "cross_val_score(estimator, X, y = None, scoring = None, cv = None, n_jobs = 1, verbose = 0, fit_params = None, pre_dispatch = '2*n_jobs')\n",
    "\n",
    "이 중 estimator, X, y, scoring, cv가 주요 파라미터!\n",
    "- estimator : Classifier / Regressor\n",
    "- X : feature dataset\n",
    "- y : lable dataset\n",
    "- scoring : 예측 성능 평가 성능 지표\n",
    "- cv : 교차 검증 폴드 수\n",
    "- 반환 값 : scoring 파라미터로 지정된 성능 지표 측정값을 배열형태로 반환\n",
    "- classifier입력 시 Stratified K 폴드 방식으로 lable값의 분포에 따라 학습/테스트 세트 분할\n",
    "- regressor 입력 시 Stratified K 폴드 방식으로 분류 불가능하므로 KFold방식으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "print('교차 검증별 정확도 : ', np.round(scores, 4))\n",
    "print('평균 검증 정확도 : ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비슷한 API로 **cross_validate()**\n",
    "\n",
    "cross_val_score는 하나의 평가 지표만 가능하지만 cross_validate는 여러 개의 평가 지표 반환 가능.\n",
    "또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
    "\n",
    "Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안 제공.\n",
    "\n",
    "Grid는 격자라는 뜻으로 촘촘하게 파라미터를 입력하면서 테스트를 하는 방식을 의미!\n",
    "\n",
    "즉, 데이터 세트를 cross-validation을 위한 학습 / 테스트 세트로 자동으로 분할한 뒤에 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터를 찾을 수 있게 해줌.\n",
    "\n",
    "튜닝하고자 하는 여러 종류의 하이퍼 파라미터를 다양하게 테스트하면서 최적의 파라미터를 편리하게 찾게 해주지만 동시에 순차적으로 파라미터를 테스트하므로 수행시간이 상대적으로 오래 걸리는 것에 유념해야 함!\n",
    "\n",
    "e.g) 결정 트리 알고리즘의 여러 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터 조합을 찾고자 한다면\n",
    "다음과 같이 파라미터의 집합을 만들고 이를 순차적으로 적용하면서 최적화를 수행 할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth' : [1, 2, 3],\n",
    "                   'min_samples_split' : [2, 3]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV 클래스의 생성자로 들어가는 주요 파라미터**\n",
    "- estimator : classifier, regressor, pipeline\n",
    "- param_grid : key + 리스트 값을 가지는 딕셔너리. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값 지정\n",
    "- scoring : 예측 성능을 측정할 평가 방법 지정. 보통은 성능 평가 지표를 지정하는 문자열(e.g accuracy)로 지정하나 별도의 성능 평가 지표 함수도 지정 가능\n",
    "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수 지정\n",
    "- refit : 생성 시 가장 최적의 하이퍼 파라미터를 찾을 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습. default = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습 덷이터와 테스트 데이터 분리\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV 객체의 fit(학습 데이터 세트) 메서드를 수행하면 학습 데이터를 cv에 기술된 폴딩 세트로 분할해 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고 그 결과를 cv_results_ 속성에 기록.\n",
    "cv_results_는 gridsearchcv의 결과 세트로서 딕셔너리 형태로 key값과 value 값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "### refit = True가 default임. True면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습 / 평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- params 칼럼에는 수행할 때마다 적용된 개별 하이퍼 파라미터값을 나타냄 \n",
    "- rank_test_score는 하이퍼 파라미터 별로 성능이 좋은 score 순위를 나타냄. 1이 가장 뛰어난 순위이며 이때의 파라미터가 최적의 하이퍼 파라미터.\n",
    "- mean_test_score는 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값\n",
    "- best_params_, best_score_속성에 최고 성능을 나타낸 하이퍼 파라미터 값과 평과 결과 값 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GTridSearchCV 최고 정확도 : 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터 : ', grid_dtree.best_params_)\n",
    "print('GTridSearchCV 최고 정확도 : {0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
